---
title: "Práctica 2: Limpieza y análisis de datos"
author: <center> David Dávila y Mónica Gómez </center> 
date: <center> 21/12/2020 </center> 
output:
  html_document:
    toc: yes
    number_sections: true
    df_print: paged
    highlight: zenburn
    code_folding: show
    theme: spacelab
    collapse: no
  pdf_document:
    toc: yes
    number_sections: true
    highlight: zenburn
    code_folding: show
    theme: spacelab
    collapse: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r message=FALSE, warning=FALSE}
getwd()
```


******
# Limpieza de los datos
******

## Carga del archivo 

```{r message=FALSE}
getwd()
```

Se procede a abrir el archivo formato .csv y examinar el tipo de datos con los que R ha interpretado cada variable. 
```{r}
mydata <- data.frame(read.csv("C:\\Users\\GOMEZM\\Documents\\AnalisisPRA2\\BankChurners.csv", header=TRUE))
df <- data.frame(mydata)
attach(df)
head(df)
```

## Análisis del archivo 

Reviso el resumen del dataframe:
```{r}
summary(df)
```

Reviso la estructura del dataframe:

```{r message=FALSE, warning=FALSE}
str(df) 
```

## Selección de los datos de interés

Para el presente proyecto se utilizarán todas las variables presentes en el juego de datos a excepción de las dos últimas que no serán de utilidad en los análisis que se planean hacer a posteriori.

```{r}
df <- df[,-(22:23)]
names(df)
```

Elaboro gráficas por variable para tener un primer acercamiento sobre su comportamiento  

```{r message=FALSE, warning=FALSE}
library(ggplot2)

par(mfrow=c(2,2))

p1 <- plot(CLIENTNUM, main="CLIENTNUM")
p2 <- plot(as.factor(Attrition_Flag), main="Attrition_Flag")
p3 <- plot(Customer_Age, main="Customer_Age")
p4 <- plot(as.factor(Gender), main="Gender")
p5 <- plot(Dependent_count, main="Dependent_count")
p6 <- plot(as.factor(Education_Level), main="Education_Level")
p7 <- plot(as.factor(Marital_Status), main="Marital_Status") 
p8 <- plot(as.factor(Income_Category), main="Income_Category")    
p9 <- plot(as.factor(Card_Category), main="Card_Category")  
p10 <- plot(Months_on_book, main="Months_on_book")
p11 <- plot(as.factor(Total_Relationship_Count), main="Total_Relationship_Count")
p12 <- plot(Months_Inactive_12_mon, main="Months_Inactive_12_mon")  
p13 <- plot(Contacts_Count_12_mon, main="Contacts_Count_12_mon")  
p14 <- plot(Credit_Limit, main="Credit_Limit")  
p15 <- plot(Total_Revolving_Bal, main="Total_Revolving_Bal")  
p16 <- plot(Avg_Open_To_Buy, main="Avg_Open_To_Buy")  
p17 <- plot(Total_Amt_Chng_Q4_Q1, main="Total_Amt_Chng_Q4_Q1")  
p18 <- plot(Total_Trans_Amt, main="Total_Trans_Amt")  
p19 <- plot(Total_Trans_Ct, main="Total_Trans_Ct")  
p20 <- plot(Total_Ct_Chng_Q4_Q1, main="Total_Ct_Chng_Q4_Q1")  
p21 <- plot(Avg_Utilization_Ratio, main="Avg_Utilization_Ratio")  
#p22 <- plot(Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1, main="Naive_Bayes_Classifier_1")  
#p23 <- plot(Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2, main="Naive_Bayes_Classifier_2")  
```

Los gráficos generados nos permiten explorar los datos de forma preliminar. Algunos de los insights que se pueden extraer son:

Variables cuantitativas: presentan una alta dispersión en sus datos.

Variables cuanlitativas: se puede observar que el banco en cuestión presenta una mayor cantidad de clientes con cuentas activas que inactivas, existen más mujeres que hombres, la mayoría están solteros o casados  con estudios terminados y que usan la tarjeta de crédito categoría “Blue”.

******
##  Normalización de los datos cuantitativos y cualitativos
******

Estas normalizaciones tienen como objetivo uniformizar los formatos. En este caso no es necesario normalizarlos. Sin embargo, los valores perdidos o valores extremos (de haberlos), se tratarán más adelante.

Se detallan los tipos de datos por variable:  

```{r}
sapply(df, function(x) class(x))
```

******
## Ceros y elementos vacíos
******

Este dataset en particular presenta una completitud del 100% como se demuestra a continuación:    

```{r}
sapply(df, function(x) sum(is.na(x)))
```
 
******
## Valores extremos
******

Se procede a hacer la exploración de outliers con el diagráma de caja y bigote, para posteriormente de acuerdo a un análisis por cada variable extraer e imputar los valores con la mediana de aquellas variables donde se haya considerado meritorio hacerlo.  

```{r}

par(mfrow=c(2,2))

p1 <- boxplot(CLIENTNUM, main="CLIENTNUM")
p3 <- boxplot(Customer_Age, main="Customer_Age")
p5 <- boxplot(Dependent_count, main="Dependent_count")
p10 <- boxplot(Months_on_book, main="Months_on_book")
p12 <- boxplot(Months_Inactive_12_mon, main="Months_Inactive_12_mon")
p13 <- boxplot(Contacts_Count_12_mon, main="Contacts_Count_12_mon")  
p14 <- boxplot(Credit_Limit, main="Credit_Limit")  
p15 <- boxplot(Total_Revolving_Bal, main="Total_Revolving_Bal")  
p16 <- boxplot(Avg_Open_To_Buy, main="Avg_Open_To_Buy")  
p17 <- boxplot(Total_Amt_Chng_Q4_Q1, main="Total_Amt_Chng_Q4_Q1")  
p18 <- boxplot(Total_Trans_Amt, main="Total_Trans_Amt")  
p19 <- boxplot(Total_Trans_Ct, main="Total_Trans_Ct")  
p20 <- boxplot(Total_Ct_Chng_Q4_Q1, main="Total_Ct_Chng_Q4_Q1")  
p21 <- boxplot(Avg_Utilization_Ratio, main="Avg_Utilization_Ratio")  
```


De los diagramas se puede extraer la siguiente información:

- Simetría de la distribución de los datos.
- Detectar la presencia de valores atípicos o outliers.
- Ver cómo es la dispersión de los puntos con la mediana, los percentiles 25 y 75 y los valores máximos y mínimos.

Al revisar los diagramas generados se encuentra que:

La distribución no es simétrica para la mayoría de variables, y es simétrica en los casos de: "Customer_Age", "Dependent_count" y "Months_on_book". 

******
### Customer_Age
******

```{r}
x<-boxplot.stats(Customer_Age)$out
idx <- which(Customer_Age %in% x)
ca <- df$Customer_Age[idx] #Valores atípicos
min(ca)
max(ca)
length(ca)
ca
```
En este caso, es un poco extraño que únicamente 2 de 10 mil clientes superen los 70 años y por ello se puede considerar que se trata de valores que probablemente se ingresaron o calcularon erróneamente. Si se tuviera la fecha de nacimiento sería fácil comprobar la edad real de ese par de clientes, sin embargo al desconocer ese dato se procede a imputar.

```{r}
df$Customer_Age[df$Customer_Age>69] <- NA #Dejamos en NA solo los más extremos
df$Customer_Age[idx]
boxplot(df$Customer_Age)
```

```{r}
idx <- which(is.na(df$Customer_Age))
length(idx) #número de valores perdidos

for (i in 1:length(idx)){
index <- idx[i]
df[index,]$Customer_Age <- median(df$Customer_Age, na.rm=TRUE ) #imputación
}
df$Customer_Age[idx] #mostramos el resultado
```

******
### Months_on_book
******

```{r}
x<-boxplot.stats(Months_on_book)$out
idx <- which(Months_on_book %in% x)
mob <- df$Months_on_book[idx] #Valores atípicos
min(mob)
max(mob)
length(mob)
```

Como se observa, la variable 'Months_on_book' tiene 386 outliers. Sin embargo, dado que representa el período de pertenencia con la entidad financiera en meses va a ser normal el encontrar clientes muy antiguos (56 meses) o muy recientes (13 meses) por lo que no se los eliminará del dataset.

******
### Months_Inactive_12_mon
******

```{r}
x<-boxplot.stats(Months_Inactive_12_mon)$out
idx <- which(Months_Inactive_12_mon %in% x)
mi <- df$Months_Inactive_12_mon[idx] #Valores atípicos
min(mi)
max(mi)
length(mi)
```

La variable 'Months_Inactive_12_mon' tiene 331 outliers. Sin embargo, dado que pueden haber clientes que han permanecido inactivos entre 0-6 meses, este podría ser un parámetro a considerar para saber si el cliente está por suspender o no algún servicio bancario. Por lo tanto, no se los eliminarán del dataset.

******
### Contacts_Count_12_mon
******

```{r}
x<-boxplot.stats(Contacts_Count_12_mon)$out
idx <- which(Contacts_Count_12_mon %in% x)
cc <- df$Contacts_Count_12_mon[idx] #Valores atípicos
min(cc)
max(cc)
length(cc)
```

La variable 'Contacts_Count_12_mon' presenta 629 outliers pero dado el contexto de que pueden haber clientes con los cuales no se ha contactado entre 0-6 meses, este podría ser un parámetro a considerar para saber si el cliente está por suspender o no algún servicio bancario. Por lo tanto, no se los eliminarán del dataset.

******
### Credit_Limit
******

```{r}
x<-boxplot.stats(Credit_Limit)$out
idx <- which(Credit_Limit %in% x)
cl <- df$Credit_Limit[idx] #Valores atípicos
min(cl)
max(cl)
length(cl)
```

Dado que el límite de crédito puede variar dependiendo de muchos factores para a un cliente en específico se opta por mantenerlos.

******
### Avg_Open_To_Buy
******

```{r}
x<-boxplot.stats(Avg_Open_To_Buy)$out
idx <- which(Avg_Open_To_Buy %in% x)
avg <- df$Avg_Open_To_Buy[idx] #Valores atípicos
min(avg)
max(avg)
length(avg)
```

Dado que la variable 'Avg_Open_To_Buy' presenta 963 outliers y representa línea de crédito abierta para compra se mantienen los valores.

******
### Total_Amt_Chng_Q4_Q1
******

```{r}
x<-boxplot.stats(Total_Amt_Chng_Q4_Q1)$out
idx <- which(Total_Amt_Chng_Q4_Q1 %in% x)
tac <- df$Total_Amt_Chng_Q4_Q1[idx] #Valores atípicos
min(tac)
max(tac)
length(tac)
```

La variable 'Total_Amt_Chng_Q4_Q1' tiene 396 outliers y muestra los cambios transaccionales que pueden ser muy variables dependiendo del perfil de cada cliente, así que se opta por mantenerlos.

******
### Total_Trans_Amt
******

```{r}
x<-boxplot.stats(Total_Trans_Amt)$out
idx <- which(Total_Trans_Amt %in% x)
tta <- df$Total_Trans_Amt[idx] #Valores atípicos
min(tta)
max(tta)
length(tta)
```

La variable 'Total_Trans_Amt' tiene 896 outliers y muestra la totalidad de cantidad de transacciones que pueden ser muy variables de persona a persona, así que se opta por mantenerlos.

******
### Total_Trans_Ct
******

```{r}
x<-boxplot.stats(Total_Trans_Ct)$out
idx <- which(Total_Trans_Ct %in% x)
ttc <- df$Total_Trans_Ct[idx] #Valores atípicos
min(ttc)
max(ttc)
length(ttc)
```

La variable 'Total_Trans_Ct' tiene 2 outliers. Es extraño que se existan únicamente dos clientes que durante los últimos 12 meses hayan realizado casi 140 transacciones. Por ello se opta por imputar esos datos.


```{r}
df$Total_Trans_Ct[df$Total_Trans_Ct>137] <- NA #Dejamos en NA solo los más extremos
df$Total_Trans_Ct[idx]
boxplot(df$Total_Trans_Ct)
```

```{r}
idx <- which(is.na(df$Total_Trans_Ct))
length(idx) #número de valores perdidos

for (i in 1:length(idx)){
index <- idx[i]
df[index,]$Total_Trans_Ct <- median(df$Total_Trans_Ct, na.rm=TRUE ) #imputación
}
df$Total_Trans_Ct[idx] #mostramos el resultado
```

******
### Total_Ct_Chng_Q4_Q1
******

```{r}
x<-boxplot.stats(Total_Ct_Chng_Q4_Q1)$out
idx <- which(Total_Ct_Chng_Q4_Q1 %in% x)
tcc <- df$Total_Ct_Chng_Q4_Q1[idx] #Valores atípicos
min(tcc)
max(tcc)
length(tcc)
```

La variable 'Total_Ct_Chng_Q4_Q1' tiene 394 outliers y muestra el cambio en el conteo de las transacciones que pueden ser muy variables de cliente a cliente, así que se opta por mantenerlos.

******
## Exportación de los datos preprocesados
******

```{r}
# Exportación de los datos limpios en formato .csv
write.csv(df, "C:\\Users\\GOMEZM\\Documents\\AnalisisPRA2\\BankChurners_clean.csv")
```


******
# Analisis de los datos
******

## Selección de los grupos de datos a analizar 
```{r message=FALSE}
library(MASS)
library(dplyr)
library(plyr)
```

Para este estudio se tomarán algunas variables de tipo categorico para observar si se comportan de un a forma distinta ante la variable que deseeamos predecir. Antes de ello se eliminará la variable CLIENTUM de nuestro conjunto de datos.

```{r message=FALSE}
data=subset(df, select=-c(CLIENTNUM))
colnames(data)
```

En este caso nos interesarán los grupos correspondientes al género, el nivel de educación y estado marital

```{r message=FALSE}
#Selección de grupos.
#Agrupación por genero.
data.femenino<-data[data$Gender=="F",]
data.masculino<-data[data$Gender=="M",]
#Agrupación por nivel de educación
data.HighSchool<-data[data$Education_Level=="High School",]
data.Graduate<-data[data$Education_Level=="Graduate",]
data.Uneducated<-data[data$Education_Level=="Uneducated",]
data.Unknown<-data[data$Education_Level=="Unknown",]
data.College<-data[data$Education_Level=="College",]
data.Postgraduate<-data[data$Education_Level=="Post-Graduate",]
data.Doctorate<-data[data$Education_Level=="Doctorate",]
#Agrupación por estado marital
data.Married<-data[data$Marital_Status=="Married",]
data.Single<-data[data$Marital_Status=="Single",]
data.UnknownStatus<-data[data$Marital_Status=="Unknown",]
data.Divorced<-data[data$Marital_Status=="Divorced",]
```

Por último dado que nuestra variable a predecir se encuentra con los valores "Existing Customer" y "Attrited Customer" se procede a cambiarla con notación binaria. Es decir, "Attrited Customer" tomará el valor 1 y "Existing Customer" tomará el valor 0.

```{r message=FALSE}
#Se convierten a dummy
data$Attrition_Flag<-ifelse(data$Attrition_Flag=="Attrited Customer",1,0)
```

## Comprobación de normalidad y homogeneidad de la varianza

Es de principal importancia dependiendo del modelo a aplicar, el realizar la correspondiente comprobación de normalidad y homogeneidad de la varianza en nuestro conjunto de datos. Por lo cual, para realizar la comprobación de nuestras variables sobre una población normalmente distribuida, se utilizará la prueba de normalidad de Anderson-Darling.

Teniendo en cuenta en $\alpha =0.05$, si obtenemos un p-valor superior al alfa mencionado anteriormente, entonces no rechazaremos nuestra hipótesis nula y los valores vendrán de una distribución/población normal.

```{r message=FALSE}
library(nortest)
col.names=colnames(data)
alpha = 0.05

for (i in 1:ncol(data)) {
  if (i == 1) cat("Variables que no siguen una distribución normal:\n")
  if (is.integer(data[[i]]) | is.numeric(data[[i]])) {
    p_val = ad.test(data[[i]])$p.value
    if (p_val < alpha) {
      cat(col.names[i])
      # Format output
      if (i < ncol(data) - 1)
      if (i %% 1 == 0) cat("\n")
    }
  }
}
```

Posterioa a ello, realizamos la comprobación sobre la homogeneidad de las varianzas con el test de Fligner.Killen. Para neustro caso, estudiaremos la homogeneidad en cuanto a los grupos conformados por las siguientes variables: Género, nivel educativo, estado marital, categoría de ingresos y categoría de la tarjeta. Recordemos que la hipótesis nula consiste en que ambas varianzas son iguales

```{r message=FALSE}
fligner.test(Attrition_Flag~Gender, data=data)
fligner.test(Attrition_Flag~Education_Level, data=data)
fligner.test(Attrition_Flag~Marital_Status, data=data)
fligner.test(Attrition_Flag~Income_Category, data=data)
fligner.test(Attrition_Flag~Card_Category, data=data)
```

Teniendo en cuenta los resultados anteriores, solamente podemos no rechazar la hipótesis nula para las variables: nivel educativo, estado marital y categoría de la tarjeta. Dado que se obtienen que el valor-p asociado a la prueba es mayor que el alfa establecido.

## Pruebas estadísticas
```{r message=FALSE}
corr_matrix <- matrix(nc = 2, nr = 0)
colnames(corr_matrix) <- c("estimate", "p-value")
# Calcular el coeficiente de correlación para cada variable cuantitativa
# con respecto al campo "precio"
for (i in 1:(ncol(data) - 1)) {
  if (is.integer(data[[i]]) | is.numeric(data[[i]])) {
    spearman_test = cor.test(data[[i]],
                             data[[1]],
                             method = "spearman")
    corr_coef = spearman_test$estimate
    p_val = spearman_test$p.value
    # Add row to matrix
    pair = matrix(ncol = 2, nrow = 1)
    pair[1][1] = corr_coef
    pair[2][1] = p_val
    corr_matrix <- rbind(corr_matrix, pair)
    rownames(corr_matrix)[nrow(corr_matrix)] <- colnames(data)[i]
  }
}

corr_matrix
```

## Modelo de regresión logística

Se plantea un primer modelo de regresión logística teniendo en cuenta que nuestra variable objetivo es binaria. Además se traen variables de interés en las cuales trataremos de predecir la estancia de los clientes dentro de la empresa. Entre dichas variables encontramos por ejemplo: edad del usuario, género, si tiene personas que dependen del usuario, nivel educativo, estado marital, categoría de ingresos, categoría de la tarjeta entre otros.

```{r message=FALSE}
logisticModelFull <- glm(Attrition_Flag ~  Customer_Age+Gender+Dependent_count+
                           Education_Level+Marital_Status+Income_Category+
                           Card_Category+Months_on_book+
                           Total_Relationship_Count+Months_Inactive_12_mon
                         +Contacts_Count_12_mon+Total_Revolving_Bal+
                           Total_Trans_Amt+Total_Trans_Ct,
                         family = "binomial",data)
summary(logisticModelFull)
```

Dentro del resumen de los resultados del modelo obtenemos que las siguientes variables son estadísticamente signficativas: Gender, Dependent_count, Educational_Level, Marital_Status, Income_Category,Card_Category, Total_Relationship_Count, Months_Inactive_12_mon, Contacts_Count_12_mon, Total_Revolving_Bal, Total_Trans_Amt y Total_Trans_Ct.

Sin embargo, utilizaremos la función stepAIC de R, la cual realiza la selección del modelo paso a paso por el criterio de información de Akaike (AIC), el cual es una medida de calidad relativa de un modelo estadístico.

```{r message=FALSE}
logisticModelNew <-  stepAIC(logisticModelFull, trace = 0)
summary(logisticModelNew)
```
Finalmente mediante esta función se elige el modelo con las siguientes variables: Customer_Age, Gender, Dependent_count, Marital_Status, Income_Category, Card_Category, Total_Relationship_Count, Months_Inactive_12_mon, Contacts_Count_12_mon, Total_Revolving_Bal, Total_Trans_Amt, Total_Trans_Ct.

## Interpreation de coeficientes (odds)

```{r message=FALSE}
odds <-  coef(logisticModelNew) %>% exp() %>% round(2)
odds
```
Una breve interpretación de los resultados obtenidos con los coeficientes u "odds", puede ser la siguiente:

* Los usuarios que se encuentran solteros aumentan la tasa de abandono en un 11%.
* Dentro de los usuarios que tienen diferentes categoráis de tarjetas se tiene que aquellos que tienen la categoría platino aumentan la tasa de abandono en un 119%.
* Una relación inversa que observamos la tasa de abandono es un un 59% menor si el usario es de género masculino comparado con las usuarias femeninas.

## Predicciones

Primero, se decide realizar una división de los datos en los conjuntos de datos de entrenamiento y de prueba. En este caso se genera una variable aleatoria que toma valores 1 y 0 gracias a que proviene de una distribución binomial con una probabilidad de 0.66.
```{r message=FALSE}
set.seed(27345)

data$isTrain <- rbinom(nrow(data),1,0.66)
train <-  data %>% filter(data$isTrain =="1")
test <- data %>%  filter(data$isTrain == "0")
```

Posterior a ello, se realiza el modelo escogido anteriomente con el conjunto de datos de entrenamiento, y se realizan las predicciones con la función predict con el conjunto de datos de prueba.

```{r message=FALSE}
LogisticTrainNew <- glm(formula = Attrition_Flag ~ Customer_Age + Gender + Dependent_count + 
                          Marital_Status + Income_Category + Card_Category + Total_Relationship_Count + 
                          Months_Inactive_12_mon + Contacts_Count_12_mon + Total_Revolving_Bal + 
                          Total_Trans_Amt + Total_Trans_Ct, family = "binomial", data = train)

#prediciton 
test$predictNew <- predict(LogisticTrainNew , type = "response" , newdata = test)
```

Para revisar que tan bien el modelo logístico predice los valores del conjunto de prueba se procede a realizar la matriz de confusión.

```{r message=FALSE}
library(readr)
library(ggplot2)
library(boot)
library(caret)
library(e1071)
predicciones=as.factor(ifelse(test = test$predictNew > 0.35, yes = 1, no = 0))
observaciones=as.factor(test$Attrition_Flag)
matriz<-confusionMatrix(observaciones, predicciones)
matriz
```

Como podemos observar, el modelo de reresión logística planteado nos da un nivel de exactitud de 88.87%, lo cual nos puede indicar la falta de variables exogenas que nos ayuden a modelar nuestro datos actuales.

```{r message=FALSE}
library(pROC)
test_prob = predict(logisticModelNew, newdata = test, type = "response")
test_roc = roc(test$Attrition_Flag ~ test_prob, plot = TRUE, print.auc = TRUE)
```

Por otra parte se realiza la grafíca ROC en la cual contiene también el valor de AUC (más conocida como el area bajo la curva ROC), hay que recordar que este valor varia entre 0 y 1, donde un modelo cuyas predicciones son un 100% incorrectas tiene un AUC de 0.0, otras donde sus predicciones son de un 100% entonces su valor de AUC asociado es de 1.0. En nuestro caso, obtuvimos un valor de AUC igual a 0.922 lo cual nos indica que las predicciones que se están haciendo se desvian un poco pero están cerca de pertenecer a un modelo "perfecto".